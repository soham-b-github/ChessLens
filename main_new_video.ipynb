{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57e994f-1e28-4f49-ad50-8fb294034b1c",
   "metadata": {},
   "source": [
    "<center> <b><h1>CHESS LENS</h1></b><br>\n",
    "<b><h2>Team BSB64</h2></b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc6a118-997a-41fb-9fe7-625b67b1fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./utils')\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb731b7-0f62-4fb1-8d5c-577aa0e3f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3649fd-c59b-4eab-a1c7-61a0c60ce9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import occupancy_detector as od\n",
    "import chessboard_processor as cbd\n",
    "import detector as md\n",
    "import visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d62dc7-b82b-4995-b8f5-e60bad48da5a",
   "metadata": {},
   "source": [
    "## Preprocess the Chessboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938e099f-0d62-43b9-b3f9-b135072d9ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QSocketNotifier: Can only be used with threads started with QThread\n"
     ]
    }
   ],
   "source": [
    "cbd.process_chessboard(\"images/board/test08.jpeg\",\"images/demo5/\",\"box\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3ed8e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move detected or initial frame\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough lines for reliable board detection",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m     visualizer\u001b[38;5;241m.\u001b[39mdisplay_board_state(board_state)\n\u001b[1;32m     34\u001b[0m     prev_board_state \u001b[38;5;241m=\u001b[39m deepcopy(board_state)\n\u001b[0;32m---> 36\u001b[0m     \u001b[43mcbd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_chessboard_from_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard_state\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages/demo7/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbox\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Display the current frame\u001b[39;00m\n\u001b[1;32m     39\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChessboard Detection\u001b[39m\u001b[38;5;124m'\u001b[39m, resized_frame)\n",
      "File \u001b[0;32m~/Documents/MSc-RKMVERI/Sem2/CV/Final-Project/ChessLens/utils/chessboard_processor.py:405\u001b[0m, in \u001b[0;36mprocess_chessboard_from_frame\u001b[0;34m(frame, output_path, prefix, debug)\u001b[0m\n\u001b[1;32m    402\u001b[0m h_lines, v_lines \u001b[38;5;241m=\u001b[39m sort_lines(lines)\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(h_lines) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m9\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v_lines) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m9\u001b[39m:\n\u001b[0;32m--> 405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough lines for reliable board detection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    407\u001b[0m intersections \u001b[38;5;241m=\u001b[39m calculate_intersections(h_lines, v_lines)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(intersections) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m81\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough lines for reliable board detection"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import cv2\n",
    "import occupancy_detector as od\n",
    "import chessboard_processor as cbd\n",
    "import detector as md\n",
    "import visualizer\n",
    "import time\n",
    "\n",
    "# Video source: use 0 for webcam or a filepath for video\n",
    "video_source = \"videos/ronu_darpan_trial.mp4\"  # Change this to your video path or use 0 for webcam\n",
    "cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "prev_board_state = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize frame if needed for processing speed\n",
    "    resized_frame = cv2.resize(frame, (800, 800))\n",
    "\n",
    "    # Process the frame using the chessboard processor\n",
    "    try:\n",
    "        board_state = cbd.process_chessboard_from_frame(resized_frame)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing frame: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Compare with previous board state to detect a move\n",
    "    if prev_board_state is None or board_state != prev_board_state:\n",
    "        print(\"Move detected or initial frame\")\n",
    "        visualizer.display_board_state(board_state)\n",
    "        prev_board_state = deepcopy(board_state)\n",
    "        \n",
    "        cbd.process_chessboard_from_frame(board_state,\"images/demo7/\",\"box\",True)\n",
    "\n",
    "    # Display the current frame\n",
    "    cv2.imshow('Chessboard Detection', resized_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438bd6b1-0013-4f65-8501-25c3f245eaba",
   "metadata": {},
   "source": [
    "## Checking the ACCURACY of OCCUPANCY Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840f4f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying different thresholds...\n",
      "\n",
      "Best Accuracy: 0.8125\n",
      "Optimal std_thresh: 40, edge_thresh: 590\n",
      "\n",
      "Status\t\tActual\tPredicted\tFilename\n",
      "Correct\t\t1\t1\t\tbox-3-true.jpg\n",
      "Correct\t\t1\t1\t\tbox-11-true.jpg\n",
      "Wrong\t\t0\t1\t\tbox-46.jpg\n",
      "Correct\t\t1\t1\t\tbox-61-true.jpg\n",
      "Correct\t\t0\t0\t\tbox-31.jpg\n",
      "Correct\t\t0\t0\t\tbox-21.jpg\n",
      "Correct\t\t0\t0\t\tbox-20.jpg\n",
      "Correct\t\t0\t0\t\tbox-16.jpg\n",
      "Correct\t\t0\t0\t\tbox-29.jpg\n",
      "Correct\t\t1\t1\t\tbox-54-true.jpg\n",
      "Correct\t\t1\t1\t\tbox-58-true.jpg\n",
      "Correct\t\t1\t1\t\tbox-51-true.jpg\n",
      "Correct\t\t1\t1\t\tbox-9-true.jpg\n",
      "Correct\t\t1\t1\t\tbox-12-true.jpg\n",
      "Correct\t\t0\t0\t\tbox-33.jpg\n",
      "Correct\t\t0\t0\t\tbox-41.jpg\n",
      "Correct\t\t1\t1\t\tbox-10-true.jpg\n",
      "Correct\t\t0\t0\t\tbox-26.jpg\n",
      "Correct\t\t1\t1\t\tbox-5-true.jpg\n",
      "Correct\t\t0\t0\t\tbox-43.jpg\n",
      "Correct\t\t1\t1\t\tbox-2-true.jpg\n",
      "Wrong\t\t0\t1\t\tbox-39.jpg\n",
      "Wrong\t\t1\t0\t\tbox-63-true.jpg\n",
      "Correct\t\t1\t1\t\tbox-15-true.jpg\n",
      "Correct\t\t1\t1\t\tbox-55-true.jpg\n",
      "Correct\t\t0\t0\t\tbox-32.jpg\n",
      "Correct\t\t0\t0\t\tbox-42.jpg\n",
      "Correct\t\t1\t1\t\tbox-7-true.jpg\n",
      "Correct\t\t1\t1\t\tbox-53-true.jpg\n",
      "Correct\t\t1\t1\t\tbox-13-true.jpg\n",
      "Correct\t\t1\t1\t\tbox-56-true.jpg\n",
      "Wrong\t\t1\t0\t\tbox-59-true.jpg\n",
      "Correct\t\t1\t1\t\tbox-60-true.jpg\n",
      "Wrong\t\t0\t1\t\tbox-44.jpg\n",
      "Wrong\t\t0\t1\t\tbox-30.jpg\n",
      "Correct\t\t0\t0\t\tbox-35.jpg\n",
      "Wrong\t\t1\t0\t\tbox-50-true.jpg\n",
      "Correct\t\t0\t0\t\tbox-24.jpg\n",
      "Correct\t\t1\t1\t\tbox-6-true.jpg\n",
      "Wrong\t\t1\t0\t\tbox-8-true.jpg\n",
      "Correct\t\t1\t1\t\tbox-49-true.jpg\n",
      "Wrong\t\t1\t0\t\tbox-52-true.jpg\n",
      "Correct\t\t0\t0\t\tbox-34.jpg\n",
      "Correct\t\t1\t1\t\tbox-62-true.jpg\n",
      "Correct\t\t0\t0\t\tbox-36.jpg\n",
      "Correct\t\t0\t0\t\tbox-28.jpg\n",
      "Correct\t\t0\t0\t\tbox-19.jpg\n",
      "Correct\t\t0\t0\t\tbox-25.jpg\n",
      "Correct\t\t1\t1\t\tbox-0-true.jpg\n",
      "Wrong\t\t1\t0\t\tbox-57-true.jpg\n",
      "Correct\t\t0\t0\t\tbox-47.jpg\n",
      "Correct\t\t0\t0\t\tbox-23.jpg\n",
      "Correct\t\t1\t1\t\tbox-14-true.jpg\n",
      "Wrong\t\t0\t1\t\tbox-22.jpg\n",
      "Correct\t\t0\t0\t\tbox-17.jpg\n",
      "Correct\t\t0\t0\t\tbox-45.jpg\n",
      "Correct\t\t0\t0\t\tbox-27.jpg\n",
      "Correct\t\t1\t1\t\tbox-48-true.jpg\n",
      "Correct\t\t1\t1\t\tbox-1-true.jpg\n",
      "Wrong\t\t0\t1\t\tbox-37.jpg\n",
      "Correct\t\t0\t0\t\tbox-18.jpg\n",
      "Correct\t\t1\t1\t\tbox-4-true.jpg\n",
      "Correct\t\t0\t0\t\tbox-40.jpg\n",
      "Correct\t\t0\t0\t\tbox-38.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# === Rule-based occupancy detector ===\n",
    "def is_occupied(img, std_thresh, edge_thresh):\n",
    "    std_dev = np.std(img)\n",
    "    edges = cv2.Canny(img, edge_thresh // 2, edge_thresh)\n",
    "    edge_density = np.sum(edges > 0) / img.size\n",
    "    return std_dev > std_thresh and edge_density > 0.02\n",
    "\n",
    "# === Load data and actual labels from filenames ===\n",
    "folder = \"images/demo5\"\n",
    "images = []\n",
    "actual_labels = []\n",
    "filenames = []\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        images.append(img)\n",
    "        actual_labels.append(1 if \"true\" in filename else 0)\n",
    "        filenames.append(filename)\n",
    "\n",
    "# === Try various combinations of thresholds ===\n",
    "best_acc = 0\n",
    "best_params = (0, 0)\n",
    "best_predictions = []\n",
    "\n",
    "print(\"Trying different thresholds...\")\n",
    "for std_thresh in range(0, 1000, 5):\n",
    "    for edge_thresh in range(0, 2000, 10):\n",
    "        predicted_labels = [\n",
    "            1 if is_occupied(img, std_thresh, edge_thresh) else 0\n",
    "            for img in images\n",
    "        ]\n",
    "        acc = accuracy_score(actual_labels, predicted_labels)\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_params = (std_thresh, edge_thresh)\n",
    "            best_predictions = predicted_labels.copy()\n",
    "\n",
    "# === Output best result summary ===\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n",
    "print(f\"Optimal std_thresh: {best_params[0]}, edge_thresh: {best_params[1]}\")\n",
    "print(\"\\nStatus\\t\\tActual\\tPredicted\\tFilename\")\n",
    "\n",
    "for actual, predicted, fname in zip(actual_labels, best_predictions, filenames):\n",
    "    status = \"Correct\" if actual == predicted else \"Wrong\"\n",
    "    print(f\"{status}\\t\\t{actual}\\t{predicted}\\t\\t{fname}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fd9c07f-6d08-4036-a35f-bc2c12fc595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0 # True Positives: Actual 1 and Pred 1\n",
    "FP = 0 # False Positives: Actual 0 but Pred 1\n",
    "FN = 0 # False Negatives: Actual 1 but Pred 0\n",
    "TN = 0 # True Negatives: Actual 0 and Pred 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd20fccb-8c17-4a32-8005-92dabe198884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in actual_labels:\n",
    "    count+=1 if i==1 else 0\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "000332c8-16bd-42f9-8513-04657c6b40ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda9a97c-d020-4f4e-bd4a-d95e8214517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "# for i in predicted_labels:\n",
    "for i in best_predictions:\n",
    "    count+=1 if i==1 else 0\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74e56d0a-ee2b-4fcf-8b87-bb31bc3d4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    TP+=1 if actual_labels[i]==1 and best_predictions[i]==1 else 0\n",
    "    FP+=1 if actual_labels[i]==0 and best_predictions[i]==1 else 0\n",
    "    FN+=1 if actual_labels[i]==1 and best_predictions[i]==0 else 0\n",
    "    TN+=1 if actual_labels[i]==0 and best_predictions[i]==0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7223c39-b740-4fbe-8dca-6fa5967369c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [0, 2, 1, 3]\n",
    "y_true = [0, 1, 2, 3]\n",
    "accuracy_score(actual_labels, best_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4e1ed09-6d09-47a4-a0aa-9711cd8411b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8125\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy = {(TP+TN)/(TP+TN+FN+FP)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c098139",
   "metadata": {},
   "source": [
    "For now, the board is at the initial position. With every next move, the board's position will change, and thus will the board matrix. Also, the board matrix needs to be converted to FEN for the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21766744",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_matrix = [\n",
    "    [\"r\", \"n\", \"b\", \"q\", \"k\", \"b\", \"n\", \"r\"],\n",
    "    [\"p\"] * 8,\n",
    "    [\"\"] * 8,\n",
    "    [\"\"] * 8,\n",
    "    [\"\"] * 8,\n",
    "    [\"\"] * 8,\n",
    "    [\"P\"] * 8,\n",
    "    [\"R\", \"N\", \"B\", \"Q\", \"K\", \"B\", \"N\", \"R\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d48152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def board_matrix_to_fen(board_matrix):\n",
    "    fen_rows = []\n",
    "    \n",
    "    for row in board_matrix:\n",
    "        fen_row = \"\"\n",
    "        empty_count = 0\n",
    "        \n",
    "        for cell in row:\n",
    "            if cell == \"\":\n",
    "                empty_count += 1\n",
    "            else:\n",
    "                if empty_count > 0:\n",
    "                    fen_row += str(empty_count)\n",
    "                    empty_count = 0\n",
    "                fen_row += cell\n",
    "        if empty_count > 0:\n",
    "            fen_row += str(empty_count)\n",
    "        \n",
    "        fen_rows.append(fen_row)\n",
    "    \n",
    "    # Join all rows with \"/\" and add standard placeholders for FEN (assuming starting position)\n",
    "    fen_position = \"/\".join(fen_rows)\n",
    "    fen = f\"{fen_position} w KQkq - 0 1\"\n",
    "    return fen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7435aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n"
     ]
    }
   ],
   "source": [
    "print(board_matrix_to_fen(board_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebda1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
